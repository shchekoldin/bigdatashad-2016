# Домашнее задание 3

Развитие социальной сети Zwitter привело к тому, что основатели стартапа дополнительно начали анализировать лайки пользователей. Также основатели хотели бы повысить качество работы социальной сети, поэтому появился интерес анализировать неуспешные ответы по запросам пользователей.

## Что надо делать?

В третьем домашнем задании вам необходимо помочь основателями решить следующие задачи:
 
  * наладить ежедневный расчет дополнительной метрики с помощью Apache Spark и предоставить доступ к рассчитанной метрики через HTTP API первого домашнего задания,
  * реализовать вычисление трех потоковых метрик по потоку событий из Apache Kafka и разместить решение на ревью.

Ниже вы можете найти более подробную информацию по следующим вопросам:

  * [Исходные данные](#Исходные-данные)
  * [Рассчитываемые метрики](#Рассчитываемые-метрики)
  * [Требования](#Требования)
  * [Критерии сдачи задания](#Критерии-сдачи-задания)
  * [Спецификация HTTP API](#Спецификация-http-api)


## Исходные данные

В этом задании используются те же исходные данные, что и в предыдущих домашних заданиях: логи доступа к веб-серверу. В дополнение к источнику данных в HDFS, в этом задании данные также доступны и в Apache Kafka.

Напомним, что из каждой записи в логе можно выделить **пользователя** и **посещенный профиль**: пользователь определяется IP-адресом, а посещенный профиль -- идентификатором, закодированном в URI запроса в виде `idNNNNN`.

К примеру, по записи

```
195.206.123.39 - - [24/Sep/2016:12:32:53 +0400] "GET /id18222 HTTP/1.1" 200 10703 "http://bing.com/" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36"
```

Можно сказать, что пользователь **195.206.123.39** посетил профиль **id18222**.

Также в данном задании вам будут важны лайки. Иногда некоторые пользователи ставят лайк профилю. В логах это соответствует хиту с параметром `like=1`, например

```
195.206.123.39 - - [24/Sep/2016:12:32:53 +0400] "GET /id18222?like=1 HTTP/1.1" 200 10703 "http://bing.com/" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36"
```

По данному хиту можно сказать, что пользователь **195.206.123.39** полайкал профиль **id18222**.

В данном домашнем задании вам будет необходимо работать как с успешными хитами (HTTP-код 200) для подсчета целевой метрики, так и с неуспешными запросами (остальные HTTP-коды) для анализа трафика сайта.

Ниже приведено несколько примеров неуспешных запросов:

```
91.102.204.107 - - [22/Nov/2016:00:00:00 +0400] "GET /favicon.ico HTTP/1.1" 404 0 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.132 Safari/537.36"
213.149.14.104 - - [22/Nov/2016:00:01:24 +0400] "GET /favicon.ico HTTP/1.1" 404 0 "-" "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; GTB7.5; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.04506.30; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; OfficeLiveConnector.1.5; OfficeLivePatch.1.3; .NET4.0C)"
195.162.93.19 - - [22/Nov/2016:00:01:25 +0400] "GET /favicon.ico HTTP/1.1" 404 0 "-" "Mozilla/5.0 (Windows NT 5.1; U; de; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 Opera 11.00"
91.221.48.183 - - [22/Nov/2016:00:01:25 +0400] "GET /favicon.ico HTTP/1.1" 404 0 "http://facebook.com/" "Mozilla/5.0 (Windows NT 6.1; rv:5.0) Gecko/20100101 Firefox/5.02"
185.112.219.6 - - [22/Nov/2016:00:01:25 +0400] "GET /favicon.ico HTTP/1.1" 404 0 "-" "Mozilla/5.0 (Linux; Android 4.4.2; K00Z Build/KVT49L) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.111 Safari/537.36"
```

Инсталляция Apache Kafka, развернутая на кластере, координируется через Zookeeper, работающий по адресу `hadoop2-10:2181`. Данные записываются в топик `bigdatashad-2016`, состоящий из *четырех* партиций.

Вы можете проверить из консоли работоспособность инсталляции следующей командой:

```
kafka-console-consumer --zookeeper hadoop2-10:2181 --topic bigdatashad-2016
```

**ВАЖНО**: При подключении из Spark Streaming вам необходимо будет указать *consumer group id*; используйте уникальные значения данного параметра. Если запустить несколько консьюмеров с одной консьюмер-группой, то произойдет перераспределение партиций между консьюмерами. В частности, в данном задании при наличии более четырех консьюмеров, какие-то из них будут простаивать.

**ВАЖНО**: При подключении из Spark Streaming не забудьте указать, что вам нужны все четыре партиции входных данных.

## Рассчитываемые метрики

Вам необходимо расчитать метрику для каждого дня логов:

 * `profile_liked_three_days` -- суммарное количество профилей, которых полайкали в течение последних трех дней подряд (то есть в день X-2, X-1, X);

По потоку событий из Kafka необходимо рассчитать следующие метрики:

  * `15_second_count` -- количество неуспешных хитов за последние 15 секунд,
  * `60_second_count` -- количество неуспешных хитов за последние 60 секунд,
  * `total_count` -- общее с момента запуска утилиты количество неуспешных хитов.

Для расчитывания метрики `profile_liked_three_days` необходимо игнорировать неуспешные запросы. Для вычисления метрик по потоку из Kafka необходимо использовать только неуспешные запросы.

## Требования

Ваше решение должно удовлетворять следующим требованиям:

  * ежедневную метрику `profile_liked_three_days` необходимо реализовать с использованием фреймворка Apache Spark;
  * ежедневная метрика `profile_liked_three_days` должна быть готова к 9 утра следующего дня (к примеру, результат за 25.11 должны быть готовы к 09:00 26.11); готовность вычисленной метрики определяется возможностью выполнения запроса через HTTP API;
  * время ответа HTTP API не должно превышать 10 секунд;
  * процесс расчета должен стабильно работать начиная с момента сдачи задания и до окончания курса, при этом ваше решение _не должно_ терять просчитанные данные за прошедшие дни (в том числе и после удаления исходных данных из HDFS).
  * подсчет метрик по потоку данных из Apache Kafka необходимо реализовать как отдельную утилитку, использующую фреймворк Apache Spark Streaming;
  * подсчет потоковых метрик должен быть реализован в одной программе (то есть одна программа считает все потоковые метрики);
  * готовую к запуску программу для расчета потоковых метрик необходимо разместить в директории для ревью `/u0/review` на сервере `hadoop2.yandex.ru`.
  
## Процесс сдачи потоковых метрик

Для сдачи задания необходимо создать в директории `/u0/review` папку с именем, равным порту HTTP API вашего первого домашнего задания, указать права на созданную папку 0770.

```
mkdir -p /u0/review/100500
chmod 770 /u0/review/100500
```

Все необходимые для запуска решения файлы должны быть внутри данного каталога. В созданной папке необходимо разместить файл `run.sh`, выполнив который возможно запустить ваше решение. Файл `run.sh` не должен принимать никаких параметров.

```
# для запуска решения должно быть достаточно выполнить следующие две команды
cd /u0/review/100500
./run.sh
# если ваше решение не запускается таким образом, то мы не сможем его проверить
```

Ожидается, что каждые 15 секунд на экран (в STDOUT) будет печататься строка вида:

```
15_second_count=NNN; 60_second_count=NNN; total_count=NNN;
```

Вместо `NNN` ожидаются расчитанные вами значения метрик. 

Например, если фактическое распределение неуспешных запросов по времени в течение двух минут после запуска вашего приложения было таким:

```
00:00 - 00:14 :  1 неуспешный запрос
00:15 - 00:29 : 10 неуспешных запросов
00:30 - 00:44 : 11 неуспешных запросов
00:45 - 00:59 :  7 неуспешных запросов
01:00 - 01:14 : 12 неуспешных запросов
01:15 - 01:29 : 19 неуспешных запросов
01:30 - 01:44 :  9 неуспешных запросов
01:45 - 01:59 : 10 неуспешных запросов
```

То ожидается, что ваше решение выведет следующие значений вычисленных метрик:

```
0m00s : "15_second_count=0; 60_second_count=0; total_count=0;"
0m15s : "15_second_count=1; 60_second_count=1; total_count=1;"
0m30s : "15_second_count=10; 60_second_count=11; total_count=11;"
0m45s : "15_second_count=11; 60_second_count=22; total_count=22;"
1m00s : "15_second_count=7; 60_second_count=29; total_count=29;"
1m15s : "15_second_count=12; 60_second_count=40; total_count=41;"
1m30s : "15_second_count=19; 60_second_count=49; total_count=60;"
1m45s : "15_second_count=9; 60_second_count=47; total_count=69;"
2m00s : "15_second_count=10; 60_second_count=50; total_count=79;"
```

Метрики по потоку будут проверяться нами вручную. Для проверки вашего решения мы будем запускать `run.sh` и сравнивать числа с нашими, каноническими. Критерий сдачи данного задания -- программа запускается по `run.sh`, работает, и выдает корректные цифры.

После реализации программы подсчета потоковых метрик и размещения файлов в вашей директории в `/u0/review`, вам необходимо создать приватный топик в Piazza c темой `HW3: $login $port` и тегом `hw3_review`. Вместо `$login` стоит указать ваш логин, вместо `$port` -- порт. В теле топика указать ваши ФИО, отделение и любую дополнительную информацию о вашем домашнем задании, которую вы сочтете нужной предоставить.

## Критерии сдачи задания

За данное домашнее задание возможно заработать 10 попугаев.

  * за вычисленную метрику `profile_liked_three_days` выдается *три* (3) попугая;
  * за вычисленную метрику `15_second_count` выдается *два* (2) попугая;
  * за вычисленную метрику `60_second_count` выдается *два* (2) попугая;
  * за вычисленную метрику `total_count` выдается *три* (3) попугая;

До 05.12 необходимо реализовать вычисление метрик и разместить решение в директории для ревью.

Если в течении подряд идущих *семи* (7) дней в период *с 05.12 до 20.12* ваш HTTP API не выдает вычисленные значения метрик / выдает неверные результаты, тогда из вашего результата будет вычтен один попугай (за каждые неработающие семь дней будет вычтено по одному попугаю).

## Спецификация HTTP API

Ваше решение должно расширить HTTP API вашего первого домашнего задания. Если вы не выполняли первое домашнее задание, создайте новое HTTP API по описанию из первого ДЗ.

HTTP API должно научиться выдавать еще одну метрику -- `profile_liked_three_days`. Если у вас нет данных за какую-либо дату, то опустите соответствующий ключ из ответа.

Пример запроса:

```
GET /api/hw1?start_date=2016-12-01&end_date=2016-12-01
```

Пример ответа:

```json
{
  "2016-12-01": {
    ...
    "profile_liked_three_days" : 4
  }
}
```
